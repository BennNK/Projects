{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NB.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"NGN4cUmai6ih","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606783250812,"user_tz":300,"elapsed":10384,"user":{"displayName":"Nina C","photoUrl":"","userId":"17309754412371274751"}},"outputId":"55ee662a-1b6d-478c-acd0-5c82ffbac782"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","CURR_DIR = \"/content/drive/My Drive\"\n","DATA_FILE = \"profiles.csv\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u-uUBZBCjMDs"},"source":["import pandas as pd\n","import numpy as np\n","import os\n","import nltk\n","import sys\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from scipy import sparse\n","np.set_printoptions(threshold=1000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T8ukeiTMjMSw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606783261698,"user_tz":300,"elapsed":4588,"user":{"displayName":"Nina C","photoUrl":"","userId":"17309754412371274751"}},"outputId":"c6c22e7d-dc94-4b8c-9704-e5f6f28addcf"},"source":["profiles = pd.read_csv(os.path.join(CURR_DIR, DATA_FILE))\n","print(profiles)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["       age  ...     status\n","0       22  ...     single\n","1       35  ...     single\n","2       38  ...  available\n","3       23  ...     single\n","4       29  ...     single\n","...    ...  ...        ...\n","59941   59  ...     single\n","59942   24  ...     single\n","59943   42  ...     single\n","59944   27  ...     single\n","59945   39  ...     single\n","\n","[59946 rows x 31 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"njFw460Nnfc7"},"source":["train_df = profiles.sample(10000, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YbyNkB9TtVgm"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p0RBLS65nyrm","executionInfo":{"status":"ok","timestamp":1606785312636,"user_tz":300,"elapsed":1042,"user":{"displayName":"Nina C","photoUrl":"","userId":"17309754412371274751"}},"outputId":"6bcdf750-151d-48b2-f1ec-675a15a8c2e9"},"source":["def parseEssay(df):\n","  df['all']=''\n","  essays=['essay0','essay1','essay2','essay3','essay4','essay5','essay6','essay7','essay8','essay9']\n","  for i in essays[0:2]:\n","    df[i]=df[i].replace(np.nan,'')\n","    df['all']=df[i]+''+df['all']\n","  essay_list = df['essay5'].to_list()\n","  #essay_list.append( df['essay1'].to_list())\n","\n","  # parses out the NaN's and leaves them empty\n","  print(\"parsing out nans\")\n","  for i in range(len(essay_list)):\n","    if not isinstance(essay_list[i], str):\n","      essay_list[i] = \"\"\n","\n","  return essay_list\n","\n","def createWordVectors(train_essays):\n","  \n","  vectorizer = CountVectorizer()\n","  vectorizer.fit(train_essays)\n","\n","  word_vecs = vectorizer.transform(train_essays)\n","\n","  return word_vecs, vectorizer\n","\n","train_essays = parseEssay(train_df)\n","word_vecs, vectorizer = createWordVectors(train_essays)\n","print(len(train_essays))\n","X = word_vecs.toarray()\n","y=(train_df.sex=='m').values.astype(np.int)\n","# for printing out the actual vocab encoding vec in case you want it\n","# print(vectorizer.vocabulary_)\n","# encoding document\n","print(X.shape)\n","print(y.shape)\n","print(len(vectorizer.vocabulary_))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["parsing out nans\n","10000\n","(10000, 13570)\n","(10000,)\n","13570\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UsXQYmJ2pjYl","executionInfo":{"status":"ok","timestamp":1606785538937,"user_tz":300,"elapsed":58669,"user":{"displayName":"Nina C","photoUrl":"","userId":"17309754412371274751"}},"outputId":"b8b4d467-13f8-4e95-c4c4-02ea503ebaa2"},"source":["kf=KFold(n_splits=10)\n","kf.get_n_splits(X)\n","tracc=[]\n","teacc=[]\n","t=0.01\n","for train_index, test_index in kf.split(X):\n","    \n","    X_train, X_test = X[train_index], X[test_index]\n","    #X_Train=X_train.sample(frac=t,replace=False,random_state=32)\n","    y_train, y_test = y[train_index], y[test_index]\n","    #y_Train=y_train.sample(frac=t,replace=False,random_state=32)\n","\n","#xtrain, xtest, ytrain, ytest = train_test_split(X, y)\n","    acc = MultinomialNB(alpha=0.1).fit(X_train, y_train)\n","    t=acc.score(X_train, y_train)\n","    st=acc.score(X_test,y_test)\n","    tracc.append(t)\n","    teacc.append(st)\n","\n","print(np.mean(tracc),np.mean(teacc))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.7529333333333333 0.5974\n"],"name":"stdout"}]}]}